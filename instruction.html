<!DOCTYPE HTML>

<html>
	<script type="text/javascript" async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<head>
	<title>Safe-Seg-24</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="stylesheet" href="assets/css/custom.html" />
</head>

<body>

	<!-- Header -->
	<header id="header">
		<div class="inner">
			<a href="index.html" class="logo">Safe-Segmentation</a>
			<!-- <a href="index.html" class="logo"><img src="images/autonue-logo-cvpr.png" width="280"></a> -->
			<nav id="nav">
				<a href="index.html">Home</a>
				<a href="dataset.html">Dataset</a>
				<a href="instruction.html">Instruction & Guideline</a>
				
				<a href="contact.html">Contact US</a>
				<a href="faq.html">FAQ</a>
				<a href="https://icpr2024.org/#" target="_blank">ICPR 2024</a>
			</nav>
		</div>
	</header>
	<a href="#menu" class="navPanelToggle"><span class="fa fa-bars"></span></a>


	<!-- One -->

	</section>	
        <section id="one" style="background-color: beige;">
		<div class="inner">
			<header>
				<h2>Evaluation</h2>
			</header>
			<p>
				<h3>Heirarchical Labeling and Tree Distance </h3>
				The essence of SmIoU lies in the introduction of hierarchical 
				penalty, a strategy that takes into account the semantic relationships between classes. 
				Heirarchical Labeling refers to the structured organization of 
				classes into a tree-like hierarchy, capturing semantic relationships 
				and dependencies between them in the context of semantic segmentation. 
				It provides a inherent semantic relationship between classes and also
				provides structured heirarchy for a comprehensive understanding of classes.  
				<p>
					Misclassifications within
					critical classes, and non-critical classes classified as critical,
					are penalized based on their distance in the class hierarchy.
					The tree distance (td) between a pair of labels is the length
					of the shortest path in the class hierarchy tree divided by
					2 
				</p>
			</p>
			<p>
				<h3>Calculation of Safe mIoU</h3>
				The calculation of SmIoU involves computing the individual safe ious
				for each class. The safe IoUs are the IoUs with a penalty for misclassification
				of that class weighted by the tree distance. The final SmIoU
				score is obtained by taking the mean of these individual safe ious. 
				
				<p>Let <i>C</i> be the set of all classes at the bottom level of the hierarchy, <i>d(c,s)</i> be the
					tree distance between class <i>c</i> and <i>s</i>, and <i>n</i> be the number of levels in the
					hierarchy, <span class="math inline">gt<sub><em>c</em></sub></span> the
					set of pixels in the ground truth with label <span
					class="math inline"><em>c</em></span> and <span
					class="math inline">pred<sub><em>s</em></sub></span> the set of pixels
					in the prediction with label <span
					class="math inline"><em>s</em></span>. We define the following
					quantities: <span class="math display">$$\begin{aligned}
					I_{c,s}^{\text{safe}} &amp;= \frac{ | \text{gt}_c \cap \text{pred}_s |}{
					| \text{gt}_c \cup \text{pred}_c |} \tag{a} \qquad
					I_{c,c} &amp;= \frac{ | \text{gt}_c \cap \text{pred}_c |}{ | \text{gt}_c
					\cup \text{pred}_c |}
					\end{aligned}$$</span></p>

				Now we define SmIoU as follows: 
				<p><span class="math display">$$\label{eq:1}
					I_c^{\text{safe}}  =
					\begin{cases}
					\begin{aligned}[t]
							I_{c,c} &amp; - \sum_{s \in C , s \neq
					c}\frac{d(c,s)}{n}I_{c,s}^{\text{safe}} &amp; \text{ if } c \in
					C_{\text{imp}} \\
							I_{c,c} &amp; - \sum_{s \in C_{\text{imp}}
					}\frac{d(c,s)}{n}I_{c,s}^{\text{safe}}&amp; \text{ else. }
					\end{aligned}
					\end{cases}$$</span></p>
					<p><span class="math display">$$\label{eq:2}
					\text{SmIoU} = \frac{\sum_{c\in C} I_c^{\text{safe}}}{|C|}$$</span></p>
			</p>
			<!-- <div class="">
				<span class="image fit">
					<img src="images/tree.png" alt = "">
			</div>  -->
			<p> 
				
			</p>
		</div>
	</section>
	<section id="one" style="background-color: antiquewhite;">
		<div class="inner">
			<header>
				<h2>Download Instructions </h2>
			</header>
			<p>     
                <li>Click to <a href="https://idd.insaan.iiit.ac.in/dataset/download/">download</a> the Dataset and more details. 
                        This will redirect you to the registration page to download the dataset.</li>
                <li>Register an account at http://idd.insaan.iiit.ac.in/.</li>
                <li>Go to Dataset > Download page in the menu.</li>
                <li>Download the IDD-AW Dataset  by clicking on 'Download' under 'IDD AW Dataset'. This will generate a 24 hour 
                        token to download the dataset.</li>
                <li>Extract the downloaded compressed file into a folder.</li>
                <li>Please run the data preparation code for generating ground truth segmentation masks as documented here: 
                        https://github.com/AutoNUE/public-code. Use the following command for segmentation mask generation:</li>
                <li>finally run `python preperation/createLabels.py --datadir $ANUE --id-type level3Id --num-workers $C `</li>
            </p>
			<p>The dataset, including training data, ground truth, and an evaluation script, will be made publicly 
                available post-competition in accordance with ICPR guidelines.
            </p>
				
		<!-- <div class="inner"> -->
			<header>
				<h2>Guidelines </h2>
			</header>
			<p> Before you can submit your first results, you need to register with CodaLab and login to participate. Only then you can submit results to the evaluation server, which will score your submission on the non-public test set.
				<header>
					<h3>Steps </h3>
				</header>
				<li>Prepare your submission in the required format, as described under the Evaluation section. 
					We expects you to share a single zip.</li>
				<li>Use the validation script from code repo  to ensure that the folder structure and number of label files in the zip file is correct. 
						All submissions count towards the overall maximum number of submissions!</li>
				<li> Go to Participate and the Submit / View Results page.</li>
				<li>Select the appropriate phase, i.e., Single Scan or Multiple Scan, for which you computed the results.</li>
				<li>Enter the required fields, where you can supply also later more details, if you need to take care of 
						anonymity in case of double blind submissions.</li>
				<li>Then you have to click "Submit" in the lower part of the page, which will open a file dialog. 
					In the file dialog, you have to select your submission zip file, which will be then uploaded.</li>				    
					<!--  - The evaluation takes roughly 10 minutes to complete and you will have the choice, which of your submission gets added to the leaderboard. -->
				Good luck with your submission!
			</p>
			<header>
				<h2>How to Participate </h2>
			</header>
			<p> Submission Policy: Only the training set is provided for learning the parameters of the algorithms. The test set should be used only for reporting the final results compared to other approaches - it must not be used in any way to train or tune systems, for example, by evaluating multiple parameters or feature choices and reporting the best results obtained. Thus, we impose an upper limit (currently 5 attempts) on the number of submissions. It is the participant's responsibility to divide the training set into proper training and validation splits, e.g., we use sequence 08 for validation. The tuned algorithms should then be run - ideally - only once on the test data and the results of the test set should not be used to adapt the approach.
			 </p>
			<p>We ask each participant to upload the final results of their algorithm/paper submission only once to the server and perform all other experiments on the validation set. If participants would like to report results in their papers for multiple versions of their algorithm (e.g., parameters or features), this must be done on the validation data and only the best performing setting of the novel method may be submitted for evaluation to our server. If comparisons to baselines from third parties (which have not been evaluated on the benchmark website) are desired, please contact us for a discussion.
			</p>
				
		</div>
	<!-- </section>	
        <section id="one">
		<div class="inner">
			<header>
				<h2>&nbsp; </h2>
			</header>
			<p>&nbsp;  </p>
		</div>
	</section> -->
            
	<!-- <section id="one">
		<div class="inner">
			<header>
				<h2>&nbsp; </h2>
			</header>
			<p>&nbsp;  </p>
		</div>
	</section> -->

	<!-- Footer -->
	<section id="footer">
		<div class="inner">
					
			<div class="copyright">
				Copyright  &copy; 2024 - All Rights Reserved   -  Safe-Segmentation-Competition-ICPR-24
			</div>
		</div>
	</section>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/skel.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>
