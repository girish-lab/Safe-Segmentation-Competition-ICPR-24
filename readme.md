
<h1 align="center">
    <a href="https://github.com/girish-lab/Safe-Segmentation-Competition-ICPR-24">ICPR 2024 Competition on Safe Segmentation of Drive Scenes in  Unstructured Traffic and Adverse Weather Conditions</a>
</h1>

<p align="center">
is a regular competition running for several months aimed at assessing the performance of semantic segmentation models in adverse weather conditions for autonomous driving. Participants are provided with the IDD-AW dataset, comprising 5000 pairs of high-quality images with pixel-level annotations, captured under adverse weather conditions such as rain, fog, low light, and snow.
</p>
    



<h2 align="center">
     Challenges  
</h2>

<p align="center">
The central challenge addressed by the competition is optimizing the Safe mIoU metric for semantic segmentation in adverse weather conditions to ensure the safety of autonomous driving systems. Semantic segmentation plays a pivotal role in enabling autonomous vehicles to understand their surroundings, but adverse weather conditions pose significant challenges, often leading to hazardous situations. The competition aims to develop robust models that accurately segment driving scenes even in adverse weather conditions, focusing on prioritizing safety-related mispredictions.
</p>

<h2 align="center">
    Awards
</h2>


    1 
    2
    3



<h2 align="center">
    Dataset details
</h2>



<p align="center">
The dataset consists of images collected in an unstructured road scenario, driving in adverse weather conditions of rain, fog, lowlight and snow. Each individual RGB image has a more detailed near-infrared image (NIR) captured simultaneously. The images are collected using JAI FS-3200D-10GE camera.
</p>


<a align="center" href="https://iddaw.github.io/"> Dataset page</a>

<a align="center" href="https://idd.insaan.iiit.ac.in/dataset/download/">Download here</a>

<p align="center">
The dataset, including training data, ground truth, and an evaluation script, will be made publicly available post-competition in accordance with ICPR guidelines.
</p>

<h2 align="center">
    Methods:
</h2>


<h2 align="center">
    Evaluation Matrics:
</h2>


    1 SafeIoU
    2 ...
    3. code [link]([https:](https://github.com/Furqan7007/IDDAW_kit))

<h2 align="center">
    Ladderboard
</h2>


<h2 align="center">
    Organigers
</h2>
    
Dr Girish Varma  Assistant Prof, C-STAR and Machine Learning Lab at IIIT Hyderabad

Furqan Ahamad, Grad Student, ML Lab, IIIT-Hyderabad

Sandeep Nagar, Grad Student, ML Lab, IIIT-Hyderabad





<h2 align="center">
    Refrence
</h2>

https://iddaw.github.io/

Furqan Ahmed Shaik, Abhishek Reddy, Nikhil Reddy Billa, Kunal Chaudhary, Sunny Manchanda, Girish Varma; Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024, pp. 4614-4623

<h2 align="center">
    FAQ:
</h2>

    1
    2
    3
    4
    5
    6
    

<h2 align="center">
    Contacts:  Names and contact info
</h2>

Furqan Ahamad, furqan.shaik@research.iiit.ac.in 

[Sandeep Nagar](https://twitter.com/NaagarRN)

[girish-lab](https://girishvarma.in/)

